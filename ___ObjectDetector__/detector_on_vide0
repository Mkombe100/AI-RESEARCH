import cv2
from ultralytics import YOLO
import time
import os  # For path validation

# Load the pre-trained YOLOv8 nano model
model = YOLO('yolov8n.pt')

# Define video file path
video_path = "video/video.mp4"  # Update if the file name or path differs
if not os.path.exists(video_path):
    print(f"Error: Video file not found at {video_path}")
    exit()

# Open video file
cap = cv2.VideoCapture(video_path)

# Check if video opened successfully
if not cap.isOpened():
    print(f"Error: Could not open video file at {video_path}. Check path or file format.")
    exit()

# Optional: Filter to specific classes (COCO dataset names)
classes_to_detect = None  # Detect all 80 classes

# Confidence threshold for detections
conf_threshold = 0.25

# Image size for inference
imgsz = 640

# FPS tracking
fps_counter = 0
start_time = time.time()

print("Starting video detection. Press 'q' to quit.")

while True:
    # Read frame from video
    ret, frame = cap.read()
    if not ret:
        print("End of video or failed to capture frame.")
        break

    # Run YOLO inference
    results = model(frame, conf=conf_threshold, imgsz=imgsz, classes=classes_to_detect, verbose=False)

    # Draw results on frame
    annotated_frame = results[0].plot()

    # Calculate and display FPS
    fps_counter += 1
    if fps_counter % 30 == 0:
        end_time = time.time()
        fps = 30 / (end_time - start_time)
        start_time = end_time
        print(f"Current FPS: {fps:.2f}")

    # Add FPS text to frame
    cv2.putText(annotated_frame, f"FPS: {fps_counter / (time.time() - start_time):.1f}",
                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    # Display the annotated frame
    cv2.imshow('YOLOv8 Video Detection', annotated_frame)

    # Break on 'q' key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Cleanup
cap.release()
cv2.destroyAllWindows()
print("Detection stopped.")
